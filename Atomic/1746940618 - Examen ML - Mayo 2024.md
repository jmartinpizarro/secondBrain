---
aliases:
  - Examen ML - Mayo 2024
tags:
"References":
cssclasses:
---
# Examen ML - Mayo 2024

1. **Overfitting vs Underfitting**
El overfitting o sobreajuste ocurre cuando nuestro modelos es capaz de memorizar los datos del dataset de entrenamiento, sin aprender de ellos. Con el dataset de entrenamiento obtiene una predicción muy alta, pero con instancias no vistas previamente dicha precisión puede bajar considerablemente, al no generalizar bien.

En el underfitting o subajuste ocurre justamente lo contrario. El modelo es incapaz de generalizar correctamente de por sí, y además es incapaz de aprender las relaciones del dataset de entrenamiento de manera correcta (usualmente ocurre cuando nuestro es modelo es demasiado simple, para unos datos muy complejos).

Para solucionar este problema, se debe de usar el **ajuste de hiperparámetros**. Con esta técnica, somos capaces de generar un modelo más o menos complejo, capaz de procesar correctamente relaciones simples o más complejas del dataset.

La validación cruzada es una herramienta muy útil para detectar el overfitting o el underfitting, pero no elimina el problema.

2. **Descripción del algoritmo de clustering jerárquico aglomerativo**
Este algoritmo hace una búsqueda aglomerativa hacia arriba, es decir, genera un árbol desde los nodos hojas hasta el raíz, basándose en las distancias entre instancias. 

El algoritmo es tal que así:
	1. Calcular la matriz de distancias entre las parejas de instancias
	2. Seleccionar aquellas instancias con la distancia más pequeña, creando un grupo.
	3. Sustituir las dos instancias en la tabla por el nuevo grupo.
	4. Repetir el paso 1.

3. **Datos desbalanceados y problemas generados**
Los datos desbalanceados (para problemas de clasificación) son aquellos datos en el que algunas clases tienen muchas menos instancias (clases minoritarias) respecto a otras clases.

Son varios los problemas ocasionados:
1. La métrica usada en estos problemas es *accuracy*. Sin embargo, no es la métrica más adecuada ya que si en el test se puede tener 99 instancias de una clase y 1 de otra, siendo posible obtener un 99% de precisión aunque el modelo generalice mal la otra clase. Usar **particiones estratificadas**.
2. Si existe un dataset con una estructura 99-1, puede ser que nuestro modelo generalice correctamente para la clase mayoritaria, pero no la minoritaria.
	1. Comparar nuestro modelo con un clasificador trivial de clase mayoritaria
	2. Usar métricas más adecuadas para problemas desbalanceados: F1 recall, balanced accuracy...
3. En el entrenamiento, puede ser que el modelo generalice correctamente la clase mayoritaria pero no la minoritaria. Se debe forzar a que el modelo entrene la clase minoritaria (class_weight) o remuestrar los datos para cambiar la proporción.